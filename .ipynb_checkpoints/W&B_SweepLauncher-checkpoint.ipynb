{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "799e2b5a-775a-49d6-98af-53d20db4394f",
   "metadata": {},
   "source": [
    "# W&B Sweep Launcher\n",
    "### $Time$ $Series$ $4th$ $Test$\n",
    "\n",
    "$Vasco$ $Mergulh√£o$ $-$ $March$ $2023$\n",
    "\n",
    "### Version 1:\n",
    " - Applies Weights and Biases Sweeps on Full Sample (i.e., 90k per country).\n",
    " - Imports Custom Functions and Networks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14e09955-8b34-471f-9666-6be4c3d7d84b",
   "metadata": {
    "tags": []
   },
   "source": [
    "### ANN Configurations:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7006642b-d7cf-492d-912c-7b3ba615f4df",
   "metadata": {
    "tags": []
   },
   "source": [
    "- #### Architecture(s)\n",
    "    - Fully Connected Auto Encoder\n",
    "        - Small (Input, 200, 200, LatDim)\n",
    "        - N2D [other papers orig ref] (Input, 500, 500, 2000, LatDim)\n",
    "    \n",
    "- #### Hyperparamenters (To Be Updated)\n",
    "    - Latent Space Size\n",
    "    - Batch Size\n",
    "        - Small test [2 - 32] and Large test [128 - 256]\n",
    "    - Learning Rate\n",
    "    - Learning Rate Scheduler\n",
    "        - Performance Schedulling\n",
    "    - Activation Functions\n",
    "        - SELU and Leaky ReLU\n",
    "    - Initializations\n",
    "        - LeCun and He (accordingly)\n",
    "    - Batch Normalization\n",
    "        - With/Without tests (note: if data is not z-scored, SELU not worth it, downgrade to ELU)\n",
    "    - Optimizers\n",
    "        - Nadam and SDG(momentum [0.9], Nesterov)\n",
    "    - Epochs\n",
    "        - 100 with Early Stopping\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f1205a3-bfeb-40f8-9106-b3598695acb6",
   "metadata": {},
   "source": [
    "---\n",
    "# Python Libraries & Custom Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9120b3d3-e71e-453e-93f4-a9c381aa9acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Library scripts\n",
    "import Transform\n",
    "from networks import ann_train, fc_small, fc_n2d, cnn_end2end_simple, cnn_small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f50a0cab-db27-40d4-be64-2087fe36b97b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "import wandb\n",
    "from wandb.keras import WandbCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a5dd1e3-056c-4512-acfb-3ce3c13b1e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fixing random seeds to ensure the reproducibility \n",
    "seed = 42\n",
    "tf.random.set_seed(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41ea8c2c-b200-4b58-bff9-938f6724c9d8",
   "metadata": {},
   "source": [
    "# Gradient Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "558484cf-c998-4dbf-8c51-e92e013b67d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPUs. On local Machine.\n"
     ]
    }
   ],
   "source": [
    "on_gradient = False\n",
    "# enable memory growth for gpu devices\n",
    "# source: https://stackoverflow.com/a/55541385/8849692\n",
    "gpu_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpu_devices:\n",
    "    on_gradient = True\n",
    "    for device in gpu_devices:\n",
    "        tf.config.experimental.set_memory_growth(device, True)\n",
    "\n",
    "if on_gradient:\n",
    "    print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "    gradient_mountedfiles = !ls /datasets/kenya-90k-set-1-w90\n",
    "    print(f'Datasets mounted: {gradient_mountedfiles}')\n",
    "else:\n",
    "    print('No GPUs. On local Machine.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6c19390-b3cd-49c5-82dc-b0618be84be2",
   "metadata": {},
   "source": [
    "---\n",
    "# Script Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b3e07d23-de4a-4f84-8ce5-fcad4e8db1b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defines Dataset for the Sweep\n",
    "dataset_name = 'Kenya_90k_Set_1_w90'\n",
    "\n",
    "if on_gradient == False:\n",
    "    # Uses name to navigate folders\n",
    "    dataset_folder = \"_\".join(dataset_name.split('_')[:-1]) #Takes out window length section\n",
    "    dataset_location = f'../Data_Storage_Processing/Data/{dataset_folder}/{dataset_name}.csv'\n",
    "    \n",
    "if  on_gradient == True:\n",
    "    dataset_location = f'/datasets/kenya-90k-set-1-w90/{dataset_name}.csv'\n",
    "\n",
    "# Zcore Data Decision\n",
    "zscore_data = True # Set to: [True/False]\n",
    "zscore_data_done = False # Always set to False. Ensures its not normalized multiple times\n",
    "\n",
    "# Model Name and Variables\n",
    "AE_Model_Name = 'CNN_Small' # Options: FC_Small, FC_N2D, CNN_E2E, CNN_Small\n",
    "latent_layer_size = 25\n",
    "\n",
    "# Sweep Names and Configurations\n",
    "if zscore_data == True:\n",
    "    Project_Name = f'DeepClust-{dataset_name}-Zscored-v1'\n",
    "else:\n",
    "    Project_Name = f'DeepClust-{dataset_name}-NOTzscored-v1'\n",
    "Sweep_Config = f'{AE_Model_Name}_sweepconfig'\n",
    "sweep_count = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fe15b696-cd03-4bd7-a797-f8e276c060ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def window_col_names(dataset_name, win_prefix = 'd'):\n",
    "    # retriving window length\n",
    "    window_len = int(dataset_name.split('_')[-1][1:]) # Gets _wXX part of name, then skips 'w' to get the number.\n",
    "    # defining window column names\n",
    "    window_cols = [None]*window_len\n",
    "    for i  in range(window_len):\n",
    "        window_cols[i] = f'{win_prefix}' + str(i+1)\n",
    "        \n",
    "    return window_cols, window_len\n",
    "\n",
    "window_cols, window_len = window_col_names(dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e9f01d65-8e14-4f9e-8951-1d56c9d73c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if AE_Model_Name == 'FC_N2D':\n",
    "    sweep_config = fc_n2d.sweep_config(name=Sweep_Config, window_len=window_len, latent_layer_size=latent_layer_size)\n",
    "    ann_network = fc_n2d.model(window_length = window_len, latent_layer_size = latent_layer_size, activation_fn = 'SELU')\n",
    "    \n",
    "elif AE_Model_Name == 'FC_Small':\n",
    "    sweep_config = fc_small.sweep_config(name=Sweep_Config, window_len=window_len, latent_layer_size=latent_layer_size)\n",
    "    ann_network = fc_small.model(window_length = window_len, latent_layer_size = latent_layer_size, activation_fn = 'SELU')\n",
    "    \n",
    "elif AE_Model_Name == 'CNN_E2E':\n",
    "    sweep_config = cnn_end2end_simple.sweep_config(name=Sweep_Config, window_len=window_len, latent_layer_size=latent_layer_size)\n",
    "    ann_network = cnn_end2end_simple.model(window_length = window_len, latent_layer_size = latent_layer_size)\n",
    "\n",
    "elif AE_Model_Name == 'CNN_Small':\n",
    "    sweep_config = cnn_small.sweep_config(name=Sweep_Config, window_len=window_len, latent_layer_size=latent_layer_size)\n",
    "    ann_network = cnn_small.model(window_length = window_len, latent_layer_size = latent_layer_size)\n",
    "    \n",
    "else:\n",
    "    print(f'ERROR: AE name {AE_Model_Name} not recognised!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "770d86a9-9d6a-45b0-a736-170a060a14f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Dense, Input, Conv1D, Conv1DTranspose, Activation, BatchNormalization, MaxPool1D, Flatten, Reshape\n",
    "from networks import ann_train\n",
    "\n",
    "window_length =90\n",
    "activation_fn = 'SELU'\n",
    "\n",
    "inputs = Input(shape= (window_length, 1))\n",
    "# CNN Enconder Block 1\n",
    "convB1_e = Conv1D(filters=32, kernel_size=5, padding='same', strides=1)(inputs)\n",
    "convB1_e = BatchNormalization()(convB1_e)\n",
    "convB1_e = Activation(ann_train.get_activation_fn(activation_fn))(convB1_e)\n",
    "convB1_e = MaxPool1D(pool_size = 3)(convB1_e)\n",
    "# CNN Enconder Block 2\n",
    "convB2_e = Conv1D(filters=64, kernel_size=3, padding='same', strides=1)(convB1_e)\n",
    "convB2_e = BatchNormalization()(convB2_e)\n",
    "convB2_e = Activation(ann_train.get_activation_fn(activation_fn))(convB2_e)\n",
    "convB2_e = MaxPool1D(pool_size = 3)(convB2_e)\n",
    "# CNN Enconder Block 3\n",
    "convB3_e = Conv1D(filters=128, kernel_size=3, padding='same', strides=1)(convB2_e)\n",
    "convB3_e = BatchNormalization()(convB3_e)\n",
    "convB3_e = Activation(ann_train.get_activation_fn(activation_fn))(convB3_e)\n",
    "convB3_e = MaxPool1D(pool_size = 3)(convB3_e)\n",
    "\n",
    "#Latent Space (no activation)\n",
    "flattend = Flatten()(convB3_e)\n",
    "encoded = Dense(latent_layer_size)(flattend)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c63823c7-f6ec-435d-bf92-2063c03f2145",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "384"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flattend.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "54c5fda8-275e-4cf8-8c69-c1dd506e093c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'method': 'random',\n",
       " 'name': 'CNN_Small_sweepconfig',\n",
       " 'metric': {'name': 'mse', 'goal': 'minimize'},\n",
       " 'parameters': {'optimizer': {'values': ['nadam', 'sgd']},\n",
       "  'latent_layer_size': {'value': 25},\n",
       "  'epochs': {'value': 100},\n",
       "  'window_length': {'value': 90},\n",
       "  'activation_fn': {'values': ['SELU', 'LeakyReLU']},\n",
       "  'learning_rate': {'distribution': 'log_uniform_values',\n",
       "   'min': 1e-05,\n",
       "   'max': 0.001},\n",
       "  'batch_size': {'distribution': 'q_log_uniform_values',\n",
       "   'q': 2,\n",
       "   'min': 100,\n",
       "   'max': 300}}}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sweep_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6c4a796f-f218-4158-8bc6-6c4ebb90fccb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 90, 1)]           0         \n",
      "                                                                 \n",
      " conv1d (Conv1D)             (None, 90, 32)            192       \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 90, 32)           128       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 90, 32)            0         \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1D  (None, 30, 32)           0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 30, 64)            6208      \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 30, 64)           256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_3 (Activation)   (None, 30, 64)            0         \n",
      "                                                                 \n",
      " max_pooling1d_1 (MaxPooling  (None, 10, 64)           0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 640)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 25)                16025     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 640)               16640     \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, 10, 64)            0         \n",
      "                                                                 \n",
      " conv1d_transpose (Conv1DTra  (None, 30, 64)           12352     \n",
      " nspose)                                                         \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 30, 64)           256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_5 (Activation)   (None, 30, 64)            0         \n",
      "                                                                 \n",
      " conv1d_transpose_1 (Conv1DT  (None, 90, 32)           10272     \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 90, 32)           128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_7 (Activation)   (None, 90, 32)            0         \n",
      "                                                                 \n",
      " conv1d_transpose_2 (Conv1DT  (None, 90, 1)            97        \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 90)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 90)                8190      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 70,744\n",
      "Trainable params: 70,360\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "ann_network.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ca547fe-2021-407d-8320-d9ec73a568f4",
   "metadata": {},
   "source": [
    "---\n",
    "# Data Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d676bb-96d7-4a9f-aeaf-ef9075048f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Data = pd.read_csv(dataset_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e44bea-432d-4334-8680-51ad57b071d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1a22afd-629e-4f1b-94ef-1bb5ea216b97",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "# Pre-Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb22a99b-63a5-47de-87c3-958d69e56835",
   "metadata": {},
   "source": [
    "---\n",
    "## Z-Scoring Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ff0a0ae-c31b-481c-a53c-f8129bd22b9c",
   "metadata": {},
   "source": [
    "This is done on a row-by-row basis.<br>\n",
    "Meaning, each window is normalized to its own Mean and Std."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f2bca9c-8742-4b7a-a5b4-ec637272e675",
   "metadata": {},
   "outputs": [],
   "source": [
    "if zscore_data == True and zscore_data_done == False:\n",
    "    Data = Transform.Zscore_Individually(Data, window_cols)\n",
    "    zscore_data_done = True\n",
    "    print('Data WAS Zscored')\n",
    "    \n",
    "elif zscore_data == True and zscore_data_done == True:\n",
    "    print('Already WAS Zscored')\n",
    "    \n",
    "elif zscore_data == False:\n",
    "    print('Data NOT Zscored')\n",
    "    \n",
    "else:\n",
    "    print('Error')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f32c5ba-c5cd-429f-83b1-04802f37c7aa",
   "metadata": {},
   "source": [
    "---\n",
    "## Train-Test Split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "266dcfe8-1780-4bd3-846e-13f729b710ee",
   "metadata": {},
   "source": [
    "### Dimitrios Sphatis Suggestion\n",
    "Make sure not to have same IDs in test(valid) and train sets.<br>\n",
    "This will reduce test accuracy, but increase generability. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afbda3a2-beee-4395-b343-329b3d722a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#As Dimitrios use:\n",
    "#https://stackoverflow.com/questions/44007496/random-sampling-with-pandas-data-frame-disjoint-groups\n",
    "# Initialize the GroupShuffleSplit.\n",
    "gss = GroupShuffleSplit(n_splits=1, test_size=0.1, random_state= seed)\n",
    "\n",
    "# Get the indexers for the split.\n",
    "idxTrain, idxTest = next(gss.split(Data, groups=Data.short_ID))\n",
    "\n",
    "# Get the split DataFrames.\n",
    "TrainData, TestData = Data.iloc[idxTrain], Data.iloc[idxTest]\n",
    "\n",
    "# Unsuring the Test and Train IDs are seperate \n",
    "assert len(set(TrainData['short_ID'].unique()).intersection(set(TestData['short_ID'].unique()))) == 0\n",
    "\n",
    "# Converting to Numpy Array\n",
    "x_train, x_test = TrainData[window_cols].to_numpy(), TestData[window_cols].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe373fa-c589-484a-979f-7bb8f0a2674f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47bfebc9-d9d1-44df-959d-946e3afdaf83",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e72bc06f-26b7-4bc1-9200-b5a7b65a8e1e",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "---\n",
    "# WandB Sweep Log in\n",
    "https://github.com/wandb/examples/blob/master/colabs/keras/Keras_param_opti_using_sweeps.ipynb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2e3e110-cecc-4b2e-ad62-a72a0932aa42",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.login()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba57bc94-c803-41bc-a1a8-c8b3be884590",
   "metadata": {},
   "source": [
    "# Sweep & Train Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "596c3d61-c6f1-42a8-847f-a81cc5e73e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, batch_size= 32, epochs= 100, lr=0.001, optimizer='nadam'):  \n",
    "    \n",
    "    tf.keras.backend.clear_session()\n",
    "    model.compile(loss=\"mse\", \n",
    "                  optimizer=ann_train.get_optimizer(lr, optimizer), \n",
    "                  metrics=[\"mse\", tf.keras.metrics.MeanAbsoluteError()])\n",
    "\n",
    "    early_stopping_cb = tf.keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)\n",
    "    lr_scheduler_cb = keras.callbacks.ReduceLROnPlateau(factor=0.5, patience=5)\n",
    "\n",
    "    model.fit(x_train, \n",
    "              x_train, \n",
    "              batch_size=batch_size, \n",
    "              epochs=epochs, \n",
    "              validation_data=(x_test, x_test), \n",
    "              callbacks=[WandbCallback(), early_stopping_cb, lr_scheduler_cb])\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e4713a-6b32-4bc1-8afd-4f93c9bd73a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sweep_train(config_defaults=None):\n",
    "    # Initialize wandb with a sample project name\n",
    "    with wandb.init(config=config_defaults):  # this gets over-written in the Sweep\n",
    "\n",
    "        # Specify the other hyperparameters to the configuration\n",
    "        wandb.config.architecture_name = AE_Model_Name\n",
    "        wandb.config.dataset_name = dataset_name\n",
    "        \n",
    "        train_go = True\n",
    "        # initialize model\n",
    "        if AE_Model_Name == 'FC_Small':\n",
    "            AE_model = fc_small.model(window_length = wandb.config.window_length,\n",
    "                                      latent_layer_size = wandb.config.latent_layer_size,\n",
    "                                      activation_fn = wandb.config.activation_fn)\n",
    "            \n",
    "        elif AE_Model_Name == 'FC_N2D':\n",
    "            AE_model = fc_n2d.model(wandb.config.window_length,\n",
    "                                    wandb.config.latent_layer_size,\n",
    "                                    wandb.config.activation_fn)\n",
    "            \n",
    "        elif AE_Model_Name == 'CNN_E2E':\n",
    "            AE_model = cnn_end2end_simple.model(wandb.config.window_length,\n",
    "                                    wandb.config.latent_layer_size,\n",
    "                                    wandb.config.activation_fn)  \n",
    "            \n",
    "        elif AE_Model_Name == 'CNN_Small':\n",
    "            AE_model = cnn_small.model(wandb.config.window_length,\n",
    "                                    wandb.config.latent_layer_size,\n",
    "                                    wandb.config.activation_fn)  \n",
    "                   \n",
    "        else:\n",
    "            print('ERROR: AE name not recognised!')\n",
    "            train_go = False\n",
    "            \n",
    "        if train_go:\n",
    "            train(AE_model, \n",
    "                  wandb.config.batch_size, \n",
    "                  wandb.config.epochs,\n",
    "                  wandb.config.learning_rate,\n",
    "                  wandb.config.optimizer)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e75e2102-26fb-4e24-978e-856983cbf259",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "# Run Sweep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be1f0f15-f71d-4da8-8319-4104432b20f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sweep_id = wandb.sweep(sweep_config, project = Project_Name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5417746c-6cc3-4e07-9b8a-b8b9293d7017",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "wandb.agent(sweep_id, function=sweep_train, count= sweep_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "432abfaa-0e16-401c-8c4b-26bed42d3854",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "626a5f08-f935-40d6-8f41-1be669af23b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
